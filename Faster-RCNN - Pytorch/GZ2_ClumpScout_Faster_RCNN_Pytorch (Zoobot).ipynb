{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "# import albumentations as A\n",
    "import pytorch_lightning as pl\n",
    "import time\n",
    "\n",
    "from torchsummary import summary\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.transform import GeneralizedRCNNTransform\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import transforms as T\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TORCH_DEVICE = 'mps' # there is currently a bug: https://github.com/pytorch/pytorch/issues/78915\n",
    "TORCH_DEVICE = 'cpu'\n",
    "CKPT_PATH = './pre_trained_models/EfficientnetB0_grayscale/'\n",
    "# CKPT_NAME = 'epoch=17-step=2808.ckpt'\n",
    "CKPT_NAME = 'epoch=18-step=2964.ckpt'\n",
    "\n",
    "DATA_PATH = '../RPN_Backbone_GZ2/Data/'\n",
    "IMAGE_PATH = DATA_PATH + 'real_pngs/'\n",
    "\n",
    "LOG_DIR = './models/Zoobot/train'\n",
    "\n",
    "# using typical split of 80:10:10\n",
    "SIZE_OF_VALIDATION_SET = 0.2\n",
    "SIZE_OF_TEST_SET = 0.1\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "CUTOUT = (50, 50, 350, 350)\n",
    "CUTOUT_ARRAY = np.array([50, 350, 50, 350])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train-set: 32270, Size of validation-set: 13894\n",
      "So, for 80 epochs we need 67005.0 steps.\n"
     ]
    }
   ],
   "source": [
    "# create dataframe for image annotations\n",
    "# loading metadata\n",
    "file_path1 = DATA_PATH + 'combined_cat.pkl'\n",
    "file_path2 = DATA_PATH + 'zoo2LocalIdMap.pkl'\n",
    "\n",
    "df_combined_cat = (pd\n",
    "    .read_pickle(file_path1)\n",
    "    #.reset_index() \n",
    "    #.explode('false_pos_prob_stats')\n",
    ")\n",
    "\n",
    "zooToLocal = pd.read_pickle(file_path2)\n",
    "df_combined_cat['local_ids'] = zooToLocal.loc[df_combined_cat.index.get_level_values(0)].to_numpy()\n",
    "\n",
    "df_combined_cat.reset_index(inplace=True)\n",
    "\n",
    "# Filter out any bulge markings that snuck through\n",
    "is_central = (\n",
    "    np.abs(0.5*(df_combined_cat['x2_normed'] + df_combined_cat['x1_normed']) - 0.5) < 0.02\n",
    "    ) & (\n",
    "    np.abs(0.5*(df_combined_cat['y2_normed'] + df_combined_cat['y1_normed']) - 0.5) < 0.02\n",
    "    )\n",
    "\n",
    "df_combined_cat = df_combined_cat.loc[~is_central | df_combined_cat['empty']].copy()\n",
    "\n",
    "# reduct to only samples with objects\n",
    "df_combined_cat = df_combined_cat[~df_combined_cat['empty']]\n",
    "\n",
    "# stick to sizes used for Zoobot training\n",
    "cutout = CUTOUT_ARRAY\n",
    "cutout_normed = CUTOUT_ARRAY/400\n",
    "\n",
    "# Convert x/y normed\n",
    "pad = 0.05\n",
    "selector = (\n",
    "    df_combined_cat['x1_normed'] > cutout_normed[0] + pad\n",
    "    ) & (\n",
    "    df_combined_cat['x2_normed'] < cutout_normed[1] - pad\n",
    "    ) & (\n",
    "    df_combined_cat['y1_normed'] > cutout_normed[2] + pad\n",
    "    ) & (\n",
    "    df_combined_cat['y2_normed'] < cutout_normed[3] - pad\n",
    "    )\n",
    "\n",
    "def convert_x_normed(x_normed):\n",
    "    x_normed = (x_normed - cutout_normed[0]) / (cutout_normed[1] - cutout_normed[0])\n",
    "    return x_normed\n",
    "\n",
    "def convert_y_normed(y_normed):\n",
    "    y_normed = (y_normed - cutout_normed[2]) / (cutout_normed[3] - cutout_normed[2])\n",
    "    return y_normed\n",
    "\n",
    "df_combined_cat['x1_normed'] = df_combined_cat.apply(lambda x: convert_x_normed(x['x1_normed']), axis=1)\n",
    "df_combined_cat['x2_normed'] = df_combined_cat.apply(lambda x: convert_x_normed(x['x2_normed']), axis=1)\n",
    "df_combined_cat['y1_normed'] = df_combined_cat.apply(lambda y: convert_y_normed(y['y1_normed']), axis=1)\n",
    "df_combined_cat['y2_normed'] = df_combined_cat.apply(lambda y: convert_y_normed(y['y2_normed']), axis=1)\n",
    "\n",
    "df_combined_cat['x1'] = df_combined_cat['x1_normed'] * (cutout[1] - cutout[0])\n",
    "df_combined_cat['x2'] = df_combined_cat['x2_normed'] * (cutout[1] - cutout[0])\n",
    "df_combined_cat['y1'] = df_combined_cat['y1_normed'] * (cutout[3] - cutout[2])\n",
    "df_combined_cat['y2'] = df_combined_cat['y2_normed'] * (cutout[3] - cutout[2])\n",
    "\n",
    "# Check, if image exists\n",
    "df_combined_cat['filename'] = IMAGE_PATH + df_combined_cat['local_ids'].apply(str) + '.png'\n",
    "df_combined_cat['file_exists'] = (df_combined_cat['filename']).apply(os.path.exists)\n",
    "\n",
    "# labels\n",
    "# 0 - background\n",
    "# 1 - Clump \n",
    "# 2 - Odd Clump\n",
    "# 3 - Improbable Clump\n",
    "# 4 - Odd Improbable Clump\n",
    "df_combined_cat['is_odd'] = np.where(df_combined_cat['mean_tool'] > 0.5, True, False)\n",
    "df_combined_cat['is_improbable'] = np.where(df_combined_cat['false_pos_prob'] > 0.7, True, False)\n",
    "\n",
    "df_combined_cat['label'] = np.select(\n",
    "    [\n",
    "        (~df_combined_cat['empty']) & (~df_combined_cat['is_odd']) & (~df_combined_cat['is_improbable']),\n",
    "        (~df_combined_cat['empty']) & (df_combined_cat['is_odd']) & (~df_combined_cat['is_improbable']),\n",
    "        (~df_combined_cat['empty']) & (~df_combined_cat['is_odd']) & (df_combined_cat['is_improbable']),\n",
    "        (~df_combined_cat['empty']) & (df_combined_cat['is_odd']) & (df_combined_cat['is_improbable']),\n",
    "    ], \n",
    "    [\n",
    "        1,\n",
    "        2,\n",
    "        2, #3\n",
    "        2, #4\n",
    "    ],\n",
    "    default = None\n",
    ")\n",
    "\n",
    "df_combined_cat['label_text'] = np.select(\n",
    "    [\n",
    "        (~df_combined_cat['empty']) & (~df_combined_cat['is_odd']) & (~df_combined_cat['is_improbable']),\n",
    "        (~df_combined_cat['empty']) & (df_combined_cat['is_odd']) & (~df_combined_cat['is_improbable']),\n",
    "        (~df_combined_cat['empty']) & (~df_combined_cat['is_odd']) & (df_combined_cat['is_improbable']),\n",
    "        (~df_combined_cat['empty']) & (df_combined_cat['is_odd']) & (df_combined_cat['is_improbable']),\n",
    "    ], \n",
    "    [\n",
    "        b'clumpy',\n",
    "        b'clumpy, odd',\n",
    "        b'clumpy, odd', # b'clumpy, improbable',\n",
    "        b'clumpy, odd', # b'clumpy, odd and improbable',\n",
    "    ],\n",
    "    default = ''\n",
    ")\n",
    "\n",
    "# get train and validation samples\n",
    "unique_ids = df_combined_cat[df_combined_cat['file_exists']]['image_id'].unique()\n",
    "unique_ids = unique_ids[:500] # for prototyping\n",
    "\n",
    "train_ids, val_ids = train_test_split(unique_ids, test_size=SIZE_OF_VALIDATION_SET + SIZE_OF_TEST_SET, random_state=42)\n",
    "df_combined_cat = df_combined_cat[df_combined_cat['file_exists']]\n",
    "\n",
    "df_combined_cat = df_combined_cat[\n",
    "    ['image_id', 'local_ids', 'filename', 'label', 'label_text',\n",
    "    # 'x1_normed', 'x2_normed', 'y1_normed', 'y2_normed']\n",
    "    'x1', 'x2', 'y1', 'y2']\n",
    "]\n",
    "\n",
    "imageGroups_train = df_combined_cat[df_combined_cat['image_id'].isin(train_ids)]\n",
    "imageGroups_valid = df_combined_cat[df_combined_cat['image_id'].isin(val_ids)]\n",
    "\n",
    "imageGroups_train = imageGroups_train.set_index(['image_id', 'local_ids', 'filename', 'label'])\n",
    "imageGroups_valid = imageGroups_valid.set_index(['image_id', 'local_ids', 'filename', 'label'])\n",
    "\n",
    "imageGroups_train.reset_index(inplace=True)\n",
    "imageGroups_valid.reset_index(inplace=True)\n",
    "\n",
    "epochs = 80\n",
    "print('Size of train-set: {}, Size of validation-set: {}'.format(len(imageGroups_train),len(imageGroups_valid)))\n",
    "print('So, for {} epochs we need {} steps.'.format(epochs, (len(imageGroups_train)+len(imageGroups_valid)/BATCH_SIZE*epochs)))\n",
    "# print('Train with Objects: {}, Train w/o objects: {}'.format(len(df_train), len(df_train_empty)))\n",
    "# print('Validation with Objects: {}, Validation w/o objects: {}'.format(len(df_val), len(df_val_empty)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving dfs\n",
    "imageGroups_train.to_pickle('imageGroups_train.pkl')\n",
    "imageGroups_valid.to_pickle('imageGroups_valid.pkl')\n",
    "imageGroups_train.to_csv('imageGroups_train.csv')\n",
    "imageGroups_valid.to_csv('imageGroups_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3189,
     "status": "ok",
     "timestamp": 1672426886562,
     "user": {
      "displayName": "Jurgen Popp",
      "userId": "11749526926963684056"
     },
     "user_tz": 0
    },
    "id": "4vYurx2q4Rdj"
   },
   "outputs": [],
   "source": [
    "# initialise Tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir=LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir $LOG_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    augs = []\n",
    "\n",
    "    augs.append(T.PILToTensor())\n",
    "    augs.append(T.ConvertImageDtype(torch.float))\n",
    "    \n",
    "    if train:\n",
    "        augs.append(T.RandomHorizontalFlip(0.5))\n",
    "    \n",
    "    return T.Compose(augs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 2442 are training and 1046 validation\n"
     ]
    }
   ],
   "source": [
    "# Dataset class and defined transformations\n",
    "import SDSSGalaxyDataset\n",
    "\n",
    "dataset_train = SDSSGalaxyDataset.SDSSGalaxyDataset(\n",
    "    dataframe=imageGroups_train,\n",
    "    image_dir=IMAGE_PATH,\n",
    "    cutout=CUTOUT,\n",
    "    transforms=get_transform(train=True)\n",
    ")\n",
    "dataset_validation = SDSSGalaxyDataset.SDSSGalaxyDataset(\n",
    "    dataframe=imageGroups_valid,\n",
    "    image_dir=IMAGE_PATH,\n",
    "    cutout=CUTOUT,\n",
    "    transforms=get_transform(train=False)\n",
    ")\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=4,\n",
    "    collate_fn=utils.collate_fn\n",
    ")\n",
    "valid_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset_validation, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=4,\n",
    "    collate_fn=utils.collate_fn\n",
    ")\n",
    "\n",
    "print(\"Count: {} are training and {} validation\".format(len(dataset_train), len(dataset_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = next(iter(train_data_loader))\n",
    "images = list(image.to(TORCH_DEVICE) for image in images)\n",
    "targets = [{k: v.to(TORCH_DEVICE) for k, v in t.items()} for t in targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    boxes = targets[i]['boxes'].cpu().numpy().astype(np.int32)\n",
    "    sample = images[i].permute(1, 2, 0).cpu().numpy()\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sample = cv2.cvtColor(sample, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    for box in boxes:\n",
    "        cv2.rectangle(sample,  # the image is in RGB, convert to BGR for cv2 annotations\n",
    "                      (box[0], box[1]),\n",
    "                      (box[2], box[3]),\n",
    "                      (0, 0, 255), 1)\n",
    "    plt.imshow(sample[:, :, ::-1])\n",
    "    # plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # Get Zoobot model and weights\n",
    "    import define_model\n",
    "    zoobot = define_model.ZoobotLightningModule(\n",
    "        output_dim=34,\n",
    "        question_index_groups=['idx1', 'idx2'],\n",
    "        include_top=True,\n",
    "        channels=1,\n",
    "        use_imagenet_weights=False,\n",
    "        always_augment=True,\n",
    "        dropout_rate=0.2,\n",
    "    )\n",
    "    checkpoint = torch.load(CKPT_PATH+CKPT_NAME, map_location=torch.device(TORCH_DEVICE))\n",
    "    zoobot.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    # select layers for feature map\n",
    "    conv_stem = torch.nn.Sequential(zoobot.model[0].features[0])\n",
    "    blocks = torch.nn.Sequential(zoobot.model[0].features[1:8])\n",
    "    conv_head = torch.nn.Sequential(zoobot.model[0].features[8])\n",
    "\n",
    "    backbone = torch.nn.Sequential(conv_stem, blocks, conv_head)\n",
    "    backbone.out_channels = 1280\n",
    "\n",
    "    # anchor_generator = AnchorGenerator(\n",
    "    #     sizes=((4, 8, 16, 32, 64),), \n",
    "    #     aspect_ratios=((0.75, 1.0, 1.25),)\n",
    "    # )\n",
    "    anchor_generator = AnchorGenerator(\n",
    "        sizes=((32, 64, 128, 256, 512),),\n",
    "        aspect_ratios=((0.5, 1.0, 2.0),)\n",
    "    )\n",
    "    \n",
    "    # Feature maps to perform RoI cropping.\n",
    "    # If backbone returns a Tensor, `featmap_names` is expected to\n",
    "    # be [0]. We can choose which feature maps to use.\n",
    "    roi_pooler = torchvision.ops.MultiScaleRoIAlign(\n",
    "        featmap_names=['0'], \n",
    "        output_size=7,\n",
    "        sampling_ratio=2\n",
    "    )\n",
    "\n",
    "    # put everything together (https://github.com/pytorch/vision/blob/main/torchvision/models/detection/faster_rcnn.py#L256)\n",
    "    model = FasterRCNN(\n",
    "        backbone, \n",
    "        num_classes=3,\n",
    "        rpn_anchor_generator=anchor_generator,\n",
    "        box_roi_pool=roi_pooler\n",
    "    )\n",
    "\n",
    "    # adjust to ensure we have only 1 channel\n",
    "    # Changes\n",
    "    grcnn = GeneralizedRCNNTransform(\n",
    "        min_size=200,\n",
    "        max_size=400,\n",
    "        image_mean=[0.485], \n",
    "        image_std=[0.229]\n",
    "    )\n",
    "    model.transform = grcnn\n",
    "\n",
    "    # freeze all bn layers\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, torch.nn.BatchNorm2d):\n",
    "            module.eval()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/env_torch/lib/python3.10/site-packages/torchvision/ops/misc.py:120: UserWarning: Don't use ConvNormActivation directly, please use Conv2dNormActivation and Conv3dNormActivation instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "NUM_EPOCHS = 70\n",
    "\n",
    "# get the model\n",
    "frcnn_model = create_model()\n",
    "\n",
    "# move model to the right device\n",
    "frcnn_model = frcnn_model.to(TORCH_DEVICE)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in frcnn_model.parameters() if p.requires_grad]\n",
    "# optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "optimizer = torch.optim.Adam(params, lr=0.001, weight_decay=0.0005)\n",
    "\n",
    "# and a learning rate scheduler which decreases the learning rate by # 10x every 3 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [ 0/77]  eta: 1:23:07  lr: 0.000014  loss: 1.8359 (1.8359)  loss_classifier: 1.1328 (1.1328)  loss_box_reg: 0.0001 (0.0001)  loss_objectness: 0.6958 (0.6958)  loss_rpn_box_reg: 0.0071 (0.0071)  time: 64.7769  data: 3.3732\n",
      "Epoch: [0]  [10/77]  eta: 1:10:36  lr: 0.000146  loss: 0.8517 (0.9517)  loss_classifier: 0.2371 (0.4002)  loss_box_reg: 0.0011 (0.0011)  loss_objectness: 0.6051 (0.5431)  loss_rpn_box_reg: 0.0079 (0.0073)  time: 63.2272  data: 0.3670\n",
      "Epoch: [0]  [20/77]  eta: 0:58:56  lr: 0.000277  loss: 0.2940 (0.5909)  loss_classifier: 0.0910 (0.2491)  loss_box_reg: 0.0016 (0.0016)  loss_objectness: 0.2542 (0.3329)  loss_rpn_box_reg: 0.0077 (0.0073)  time: 61.8995  data: 0.0423\n",
      "Epoch: [0]  [30/77]  eta: 1:10:48  lr: 0.000408  loss: 0.1224 (0.4326)  loss_classifier: 0.0704 (0.1909)  loss_box_reg: 0.0021 (0.0018)  loss_objectness: 0.0288 (0.2332)  loss_rpn_box_reg: 0.0061 (0.0067)  time: 105.3476  data: 0.0140\n",
      "Epoch: [0]  [40/77]  eta: 0:50:47  lr: 0.000540  loss: 0.0649 (0.3428)  loss_classifier: 0.0365 (0.1524)  loss_box_reg: 0.0021 (0.0019)  loss_objectness: 0.0219 (0.1818)  loss_rpn_box_reg: 0.0052 (0.0067)  time: 103.7158  data: 0.0111\n",
      "Epoch: [0]  [50/77]  eta: 0:35:01  lr: 0.000671  loss: 0.0456 (0.2840)  loss_classifier: 0.0212 (0.1262)  loss_box_reg: 0.0018 (0.0019)  loss_objectness: 0.0175 (0.1494)  loss_rpn_box_reg: 0.0059 (0.0065)  time: 58.3981  data: 0.0101\n",
      "Epoch: [0]  [60/77]  eta: 0:21:08  lr: 0.000803  loss: 0.0364 (0.2432)  loss_classifier: 0.0163 (0.1080)  loss_box_reg: 0.0010 (0.0017)  loss_objectness: 0.0140 (0.1271)  loss_rpn_box_reg: 0.0056 (0.0063)  time: 58.7045  data: 0.0087\n",
      "Epoch: [0]  [70/77]  eta: 0:08:23  lr: 0.000934  loss: 0.0352 (0.2136)  loss_classifier: 0.0138 (0.0948)  loss_box_reg: 0.0009 (0.0016)  loss_objectness: 0.0130 (0.1111)  loss_rpn_box_reg: 0.0051 (0.0061)  time: 56.6382  data: 0.0080\n",
      "Epoch: [0]  [76/77]  eta: 0:01:09  lr: 0.001000  loss: 0.0342 (0.1997)  loss_classifier: 0.0138 (0.0886)  loss_box_reg: 0.0009 (0.0016)  loss_objectness: 0.0135 (0.1035)  loss_rpn_box_reg: 0.0049 (0.0060)  time: 53.2373  data: 0.0060\n",
      "Epoch: [0] Total time: 1:30:03 (70.1739 s / it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/33]  eta: 0:04:47  model_time: 6.9403 (6.9403)  evaluator_time: 0.0094 (0.0094)  time: 8.7054  data: 1.7556\n",
      "Test:  [32/33]  eta: 0:00:06  model_time: 6.8803 (6.7902)  evaluator_time: 0.0069 (0.0073)  time: 6.7952  data: 0.0054\n",
      "Test: Total time: 0:04:06 (7.4641 s / it)\n",
      "Averaged stats: model_time: 6.8803 (6.7902)  evaluator_time: 0.0069 (0.0073)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.39s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Epoch: [1]  [ 0/77]  eta: 1:13:30  lr: 0.001000  loss: 0.0351 (0.0351)  loss_classifier: 0.0158 (0.0158)  loss_box_reg: 0.0006 (0.0006)  loss_objectness: 0.0140 (0.0140)  loss_rpn_box_reg: 0.0047 (0.0047)  time: 57.2835  data: 3.1259\n",
      "Epoch: [1]  [10/77]  eta: 1:02:02  lr: 0.001000  loss: 0.0344 (0.0345)  loss_classifier: 0.0148 (0.0145)  loss_box_reg: 0.0010 (0.0011)  loss_objectness: 0.0140 (0.0141)  loss_rpn_box_reg: 0.0045 (0.0048)  time: 55.5541  data: 0.2899\n",
      "Epoch: [1]  [20/77]  eta: 0:53:42  lr: 0.001000  loss: 0.0337 (0.0333)  loss_classifier: 0.0144 (0.0141)  loss_box_reg: 0.0010 (0.0009)  loss_objectness: 0.0140 (0.0139)  loss_rpn_box_reg: 0.0038 (0.0044)  time: 56.4996  data: 0.0077\n",
      "Epoch: [1]  [30/77]  eta: 0:44:51  lr: 0.001000  loss: 0.0319 (0.0325)  loss_classifier: 0.0131 (0.0137)  loss_box_reg: 0.0006 (0.0008)  loss_objectness: 0.0141 (0.0138)  loss_rpn_box_reg: 0.0038 (0.0042)  time: 58.2020  data: 0.0080\n",
      "Epoch: [1]  [40/77]  eta: 0:35:21  lr: 0.001000  loss: 0.0291 (0.0313)  loss_classifier: 0.0122 (0.0132)  loss_box_reg: 0.0003 (0.0007)  loss_objectness: 0.0125 (0.0134)  loss_rpn_box_reg: 0.0032 (0.0039)  time: 58.1814  data: 0.0083\n",
      "Epoch: [1]  [50/77]  eta: 0:25:51  lr: 0.001000  loss: 0.0291 (0.0308)  loss_classifier: 0.0124 (0.0131)  loss_box_reg: 0.0004 (0.0007)  loss_objectness: 0.0124 (0.0133)  loss_rpn_box_reg: 0.0031 (0.0038)  time: 57.7971  data: 0.0084\n",
      "Epoch: [1]  [60/77]  eta: 0:16:18  lr: 0.001000  loss: 0.0303 (0.0310)  loss_classifier: 0.0132 (0.0132)  loss_box_reg: 0.0008 (0.0008)  loss_objectness: 0.0131 (0.0133)  loss_rpn_box_reg: 0.0034 (0.0037)  time: 57.9935  data: 0.0088\n",
      "Epoch: [1]  [70/77]  eta: 0:06:42  lr: 0.001000  loss: 0.0295 (0.0308)  loss_classifier: 0.0126 (0.0131)  loss_box_reg: 0.0009 (0.0008)  loss_objectness: 0.0130 (0.0133)  loss_rpn_box_reg: 0.0029 (0.0036)  time: 57.6427  data: 0.0085\n",
      "Epoch: [1]  [76/77]  eta: 0:00:56  lr: 0.001000  loss: 0.0292 (0.0308)  loss_classifier: 0.0123 (0.0131)  loss_box_reg: 0.0006 (0.0007)  loss_objectness: 0.0127 (0.0133)  loss_rpn_box_reg: 0.0029 (0.0036)  time: 55.4067  data: 0.0067\n",
      "Epoch: [1] Total time: 1:13:27 (57.2388 s / it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/33]  eta: 0:04:59  model_time: 7.5445 (7.5445)  evaluator_time: 0.0067 (0.0067)  time: 9.0889  data: 1.5376\n",
      "Test:  [32/33]  eta: 0:00:07  model_time: 7.3558 (7.3049)  evaluator_time: 0.0048 (0.0057)  time: 7.2720  data: 0.0057\n",
      "Test: Total time: 0:04:23 (7.9703 s / it)\n",
      "Averaged stats: model_time: 7.3558 (7.3049)  evaluator_time: 0.0048 (0.0057)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Epoch: [2]  [ 0/77]  eta: 1:17:56  lr: 0.001000  loss: 0.0310 (0.0310)  loss_classifier: 0.0142 (0.0142)  loss_box_reg: 0.0014 (0.0014)  loss_objectness: 0.0130 (0.0130)  loss_rpn_box_reg: 0.0025 (0.0025)  time: 60.7400  data: 3.1248\n",
      "Epoch: [2]  [10/77]  eta: 1:05:19  lr: 0.001000  loss: 0.0299 (0.0314)  loss_classifier: 0.0132 (0.0135)  loss_box_reg: 0.0006 (0.0008)  loss_objectness: 0.0130 (0.0135)  loss_rpn_box_reg: 0.0038 (0.0037)  time: 58.5025  data: 0.2932\n",
      "Epoch: [2]  [20/77]  eta: 0:55:14  lr: 0.001000  loss: 0.0295 (0.0305)  loss_classifier: 0.0127 (0.0129)  loss_box_reg: 0.0004 (0.0006)  loss_objectness: 0.0134 (0.0133)  loss_rpn_box_reg: 0.0034 (0.0036)  time: 58.0287  data: 0.0087\n",
      "Epoch: [2]  [30/77]  eta: 0:45:21  lr: 0.001000  loss: 0.0302 (0.0310)  loss_classifier: 0.0128 (0.0133)  loss_box_reg: 0.0006 (0.0007)  loss_objectness: 0.0135 (0.0135)  loss_rpn_box_reg: 0.0034 (0.0035)  time: 57.5802  data: 0.0302\n",
      "Epoch: [2]  [40/77]  eta: 0:35:38  lr: 0.001000  loss: 0.0320 (0.0309)  loss_classifier: 0.0133 (0.0132)  loss_box_reg: 0.0006 (0.0007)  loss_objectness: 0.0143 (0.0135)  loss_rpn_box_reg: 0.0035 (0.0035)  time: 57.4275  data: 0.0297\n",
      "Epoch: [2]  [50/77]  eta: 0:26:03  lr: 0.001000  loss: 0.0307 (0.0306)  loss_classifier: 0.0124 (0.0130)  loss_box_reg: 0.0005 (0.0007)  loss_objectness: 0.0133 (0.0135)  loss_rpn_box_reg: 0.0032 (0.0035)  time: 57.8941  data: 0.0080\n",
      "Epoch: [2]  [60/77]  eta: 0:16:23  lr: 0.001000  loss: 0.0307 (0.0307)  loss_classifier: 0.0131 (0.0131)  loss_box_reg: 0.0004 (0.0006)  loss_objectness: 0.0134 (0.0135)  loss_rpn_box_reg: 0.0030 (0.0034)  time: 57.9629  data: 0.0081\n",
      "Epoch: [2]  [70/77]  eta: 0:06:45  lr: 0.001000  loss: 0.0300 (0.0304)  loss_classifier: 0.0135 (0.0131)  loss_box_reg: 0.0006 (0.0006)  loss_objectness: 0.0129 (0.0134)  loss_rpn_box_reg: 0.0028 (0.0033)  time: 57.9254  data: 0.0082\n",
      "Epoch: [2]  [76/77]  eta: 0:00:57  lr: 0.001000  loss: 0.0289 (0.0301)  loss_classifier: 0.0126 (0.0130)  loss_box_reg: 0.0004 (0.0006)  loss_objectness: 0.0126 (0.0133)  loss_rpn_box_reg: 0.0028 (0.0033)  time: 55.8745  data: 0.0077\n",
      "Epoch: [2] Total time: 1:13:55 (57.6094 s / it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/33]  eta: 0:04:52  model_time: 7.3538 (7.3538)  evaluator_time: 0.0046 (0.0046)  time: 8.8527  data: 1.4941\n",
      "Test:  [32/33]  eta: 0:00:07  model_time: 7.1969 (7.1466)  evaluator_time: 0.0040 (0.0043)  time: 7.1134  data: 0.0063\n",
      "Test: Total time: 0:04:17 (7.8099 s / it)\n",
      "Averaged stats: model_time: 7.1969 (7.1466)  evaluator_time: 0.0040 (0.0043)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.06s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Epoch: [3]  [ 0/77]  eta: 1:17:24  lr: 0.000100  loss: 0.0280 (0.0280)  loss_classifier: 0.0129 (0.0129)  loss_box_reg: 0.0015 (0.0015)  loss_objectness: 0.0112 (0.0112)  loss_rpn_box_reg: 0.0024 (0.0024)  time: 60.3138  data: 3.1165\n",
      "Epoch: [3]  [10/77]  eta: 1:03:48  lr: 0.000100  loss: 0.0289 (0.0293)  loss_classifier: 0.0128 (0.0131)  loss_box_reg: 0.0006 (0.0007)  loss_objectness: 0.0128 (0.0129)  loss_rpn_box_reg: 0.0025 (0.0026)  time: 57.1432  data: 0.2917\n",
      "Epoch: [3]  [20/77]  eta: 0:54:26  lr: 0.000100  loss: 0.0289 (0.0289)  loss_classifier: 0.0128 (0.0129)  loss_box_reg: 0.0004 (0.0006)  loss_objectness: 0.0128 (0.0129)  loss_rpn_box_reg: 0.0024 (0.0025)  time: 57.1481  data: 0.0092\n",
      "Epoch: [3]  [30/77]  eta: 0:44:57  lr: 0.000100  loss: 0.0261 (0.0280)  loss_classifier: 0.0118 (0.0125)  loss_box_reg: 0.0003 (0.0005)  loss_objectness: 0.0120 (0.0126)  loss_rpn_box_reg: 0.0023 (0.0024)  time: 57.5435  data: 0.0078\n",
      "Epoch: [3]  [40/77]  eta: 0:35:30  lr: 0.000100  loss: 0.0267 (0.0279)  loss_classifier: 0.0117 (0.0124)  loss_box_reg: 0.0003 (0.0005)  loss_objectness: 0.0120 (0.0125)  loss_rpn_box_reg: 0.0024 (0.0024)  time: 57.8737  data: 0.0079\n",
      "Epoch: [3]  [50/77]  eta: 0:33:59  lr: 0.000100  loss: 0.0269 (0.0275)  loss_classifier: 0.0123 (0.0123)  loss_box_reg: 0.0007 (0.0005)  loss_objectness: 0.0119 (0.0123)  loss_rpn_box_reg: 0.0022 (0.0024)  time: 103.6741  data: 0.0089\n",
      "Epoch: [3]  [60/77]  eta: 0:20:35  lr: 0.000100  loss: 0.0275 (0.0277)  loss_classifier: 0.0118 (0.0123)  loss_box_reg: 0.0007 (0.0006)  loss_objectness: 0.0121 (0.0124)  loss_rpn_box_reg: 0.0021 (0.0024)  time: 103.6676  data: 0.0091\n",
      "Epoch: [3]  [70/77]  eta: 0:08:15  lr: 0.000100  loss: 0.0281 (0.0278)  loss_classifier: 0.0121 (0.0124)  loss_box_reg: 0.0006 (0.0006)  loss_objectness: 0.0124 (0.0124)  loss_rpn_box_reg: 0.0023 (0.0024)  time: 58.4451  data: 0.0311\n",
      "Epoch: [3]  [76/77]  eta: 0:01:09  lr: 0.000100  loss: 0.0286 (0.0278)  loss_classifier: 0.0121 (0.0124)  loss_box_reg: 0.0006 (0.0006)  loss_objectness: 0.0121 (0.0124)  loss_rpn_box_reg: 0.0024 (0.0024)  time: 56.6260  data: 0.0294\n",
      "Epoch: [3] Total time: 1:29:12 (69.5128 s / it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/33]  eta: 0:05:04  model_time: 7.5917 (7.5917)  evaluator_time: 0.0056 (0.0056)  time: 9.2247  data: 1.6273\n",
      "Test:  [32/33]  eta: 0:00:07  model_time: 7.3914 (7.3567)  evaluator_time: 0.0026 (0.0033)  time: 7.3123  data: 0.0056\n",
      "Test: Total time: 0:04:24 (8.0227 s / it)\n",
      "Averaged stats: model_time: 7.3914 (7.3567)  evaluator_time: 0.0026 (0.0033)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Epoch: [4]  [ 0/77]  eta: 1:20:39  lr: 0.000100  loss: 0.0287 (0.0287)  loss_classifier: 0.0128 (0.0128)  loss_box_reg: 0.0002 (0.0002)  loss_objectness: 0.0129 (0.0129)  loss_rpn_box_reg: 0.0028 (0.0028)  time: 62.8493  data: 3.1277\n",
      "Epoch: [4]  [10/77]  eta: 1:06:31  lr: 0.000100  loss: 0.0275 (0.0275)  loss_classifier: 0.0121 (0.0124)  loss_box_reg: 0.0003 (0.0005)  loss_objectness: 0.0126 (0.0125)  loss_rpn_box_reg: 0.0022 (0.0021)  time: 59.5764  data: 0.2945\n",
      "Epoch: [4]  [20/77]  eta: 0:56:27  lr: 0.000100  loss: 0.0263 (0.0268)  loss_classifier: 0.0116 (0.0118)  loss_box_reg: 0.0003 (0.0005)  loss_objectness: 0.0122 (0.0123)  loss_rpn_box_reg: 0.0022 (0.0022)  time: 59.2508  data: 0.0113\n",
      "Epoch: [4]  [30/77]  eta: 0:46:27  lr: 0.000100  loss: 0.0269 (0.0271)  loss_classifier: 0.0114 (0.0120)  loss_box_reg: 0.0004 (0.0006)  loss_objectness: 0.0126 (0.0122)  loss_rpn_box_reg: 0.0023 (0.0022)  time: 59.1502  data: 0.0096\n",
      "Epoch: [4]  [40/77]  eta: 0:36:34  lr: 0.000100  loss: 0.0281 (0.0270)  loss_classifier: 0.0122 (0.0120)  loss_box_reg: 0.0007 (0.0007)  loss_objectness: 0.0124 (0.0122)  loss_rpn_box_reg: 0.0023 (0.0022)  time: 59.1953  data: 0.0087\n",
      "Epoch: [4]  [50/77]  eta: 0:26:43  lr: 0.000100  loss: 0.0284 (0.0273)  loss_classifier: 0.0123 (0.0121)  loss_box_reg: 0.0007 (0.0007)  loss_objectness: 0.0124 (0.0123)  loss_rpn_box_reg: 0.0022 (0.0022)  time: 59.4966  data: 0.0086\n",
      "Epoch: [4]  [60/77]  eta: 0:16:48  lr: 0.000100  loss: 0.0266 (0.0272)  loss_classifier: 0.0120 (0.0120)  loss_box_reg: 0.0005 (0.0007)  loss_objectness: 0.0129 (0.0123)  loss_rpn_box_reg: 0.0022 (0.0022)  time: 59.3062  data: 0.0083\n",
      "Epoch: [4]  [70/77]  eta: 0:06:54  lr: 0.000100  loss: 0.0271 (0.0272)  loss_classifier: 0.0116 (0.0120)  loss_box_reg: 0.0005 (0.0007)  loss_objectness: 0.0122 (0.0123)  loss_rpn_box_reg: 0.0021 (0.0022)  time: 58.9235  data: 0.0082\n",
      "Epoch: [4]  [76/77]  eta: 0:00:58  lr: 0.000100  loss: 0.0269 (0.0271)  loss_classifier: 0.0116 (0.0120)  loss_box_reg: 0.0006 (0.0007)  loss_objectness: 0.0120 (0.0122)  loss_rpn_box_reg: 0.0021 (0.0022)  time: 56.6180  data: 0.0079\n",
      "Epoch: [4] Total time: 1:15:34 (58.8888 s / it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/33]  eta: 0:05:05  model_time: 7.5790 (7.5790)  evaluator_time: 0.0038 (0.0038)  time: 9.2650  data: 1.6821\n",
      "Test:  [32/33]  eta: 0:00:07  model_time: 7.3687 (7.3246)  evaluator_time: 0.0030 (0.0031)  time: 7.2895  data: 0.0063\n",
      "Test: Total time: 0:04:24 (8.0054 s / it)\n",
      "Averaged stats: model_time: 7.3687 (7.3246)  evaluator_time: 0.0030 (0.0031)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Epoch: [5]  [ 0/77]  eta: 1:20:20  lr: 0.000100  loss: 0.0272 (0.0272)  loss_classifier: 0.0116 (0.0116)  loss_box_reg: 0.0006 (0.0006)  loss_objectness: 0.0128 (0.0128)  loss_rpn_box_reg: 0.0021 (0.0021)  time: 62.6087  data: 3.1386\n",
      "Epoch: [5]  [10/77]  eta: 1:05:57  lr: 0.000100  loss: 0.0261 (0.0262)  loss_classifier: 0.0116 (0.0115)  loss_box_reg: 0.0006 (0.0006)  loss_objectness: 0.0115 (0.0120)  loss_rpn_box_reg: 0.0021 (0.0021)  time: 59.0613  data: 0.2951\n",
      "Epoch: [5]  [20/77]  eta: 0:55:58  lr: 0.000100  loss: 0.0261 (0.0265)  loss_classifier: 0.0116 (0.0117)  loss_box_reg: 0.0004 (0.0005)  loss_objectness: 0.0113 (0.0120)  loss_rpn_box_reg: 0.0022 (0.0022)  time: 58.7275  data: 0.0100\n",
      "Epoch: [5]  [30/77]  eta: 0:46:09  lr: 0.000100  loss: 0.0262 (0.0267)  loss_classifier: 0.0123 (0.0120)  loss_box_reg: 0.0006 (0.0007)  loss_objectness: 0.0113 (0.0119)  loss_rpn_box_reg: 0.0022 (0.0022)  time: 58.8547  data: 0.0080\n",
      "Epoch: [5]  [40/77]  eta: 0:36:17  lr: 0.000100  loss: 0.0277 (0.0271)  loss_classifier: 0.0127 (0.0122)  loss_box_reg: 0.0007 (0.0007)  loss_objectness: 0.0120 (0.0120)  loss_rpn_box_reg: 0.0022 (0.0022)  time: 58.7904  data: 0.0080\n",
      "Epoch: [5]  [50/77]  eta: 0:26:27  lr: 0.000100  loss: 0.0276 (0.0272)  loss_classifier: 0.0125 (0.0122)  loss_box_reg: 0.0005 (0.0007)  loss_objectness: 0.0120 (0.0121)  loss_rpn_box_reg: 0.0022 (0.0022)  time: 58.6373  data: 0.0081\n",
      "Epoch: [5]  [60/77]  eta: 0:16:40  lr: 0.000100  loss: 0.0262 (0.0269)  loss_classifier: 0.0119 (0.0121)  loss_box_reg: 0.0006 (0.0007)  loss_objectness: 0.0116 (0.0120)  loss_rpn_box_reg: 0.0019 (0.0021)  time: 58.9175  data: 0.0084\n"
     ]
    }
   ],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(\n",
    "        frcnn_model, \n",
    "        optimizer, \n",
    "        train_data_loader, \n",
    "        TORCH_DEVICE, \n",
    "        epoch, \n",
    "        print_freq=10,\n",
    "        scaler=None,\n",
    "        # tb_writer=writer\n",
    "        tb_writer=None\n",
    "    )\n",
    "    \n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    # evaluate on the test dataset\n",
    "    evaluate(\n",
    "        frcnn_model, \n",
    "        valid_data_loader, \n",
    "        device=TORCH_DEVICE\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('env_torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c186b54c8cf1ccf367fb8bdf3e071efe85839a5daed090332edb040d14e1fa50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
