{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pytorch_lightning as pl\n",
    "import time\n",
    "\n",
    "from torchsummary import summary\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.transform import GeneralizedRCNNTransform\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "from PIL import Image, ImageDraw\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import transforms as T\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TORCH_DEVICE = 'mps' # there is currently a bug: https://github.com/pytorch/pytorch/issues/78915\n",
    "TORCH_DEVICE = 'cpu'\n",
    "CKPT_PATH = './pre_trained_models/Zoobot_Clumps_Resnet/'\n",
    "CKPT_NAME = 'Zoobot_Clump_Classifier_36.pth'\n",
    "\n",
    "DATA_PATH = '../RPN_Backbone_GZ2/Data/'\n",
    "IMAGE_PATH = DATA_PATH + 'real_pngs/'\n",
    "\n",
    "MODEL_DIR = './models/Pytorch_Resnet_Zoobot_Clumps/'\n",
    "LOG_DIR = MODEL_DIR + 'train'\n",
    "MODEL_NAME = 'FRCNN_Resnet_Zoobot_Clumps'\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "CUTOUT = (100, 100, 300, 300)\n",
    "CUTOUT_ARRAY = np.array([100, 300, 100, 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3189,
     "status": "ok",
     "timestamp": 1672426886562,
     "user": {
      "displayName": "Jurgen Popp",
      "userId": "11749526926963684056"
     },
     "user_tz": 0
    },
    "id": "4vYurx2q4Rdj"
   },
   "outputs": [],
   "source": [
    "# initialise Tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir=LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train and validation dfs\n",
    "imageGroups_train = pd.read_pickle('./imageGroups_train.pkl')\n",
    "imageGroups_valid = pd.read_pickle('./imageGroups_valid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    augs = []\n",
    "\n",
    "    augs.append(T.PILToTensor())\n",
    "    augs.append(T.ConvertImageDtype(torch.float))\n",
    "    \n",
    "    if train:\n",
    "        augs.append(T.RandomHorizontalFlip(0.5))\n",
    "    \n",
    "    return T.Compose(augs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 35542 are training and 8886 validation\n"
     ]
    }
   ],
   "source": [
    "# Dataset class and defined transformations\n",
    "import SDSSGalaxyDataset\n",
    "\n",
    "dataset_train = SDSSGalaxyDataset.SDSSGalaxyDataset(\n",
    "    dataframe=imageGroups_train,\n",
    "    image_dir=IMAGE_PATH,\n",
    "    cutout=CUTOUT,\n",
    "    colour=True,\n",
    "    transforms=get_transform(train=True)\n",
    ")\n",
    "dataset_validation = SDSSGalaxyDataset.SDSSGalaxyDataset(\n",
    "    dataframe=imageGroups_valid,\n",
    "    image_dir=IMAGE_PATH,\n",
    "    cutout=CUTOUT,\n",
    "    colour=True,\n",
    "    transforms=get_transform(train=False)\n",
    ")\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=4,\n",
    "    collate_fn=utils.collate_fn\n",
    ")\n",
    "valid_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset_validation, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=4,\n",
    "    collate_fn=utils.collate_fn\n",
    ")\n",
    "\n",
    "print(\"Count: {} are training and {} validation\".format(len(dataset_train), len(dataset_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1672212957006,
     "user": {
      "displayName": "Jurgen Popp",
      "userId": "11749526926963684056"
     },
     "user_tz": 0
    },
    "id": "6MrzmG5hm1ch"
   },
   "outputs": [],
   "source": [
    "def get_model(num_classes=2, trainable_layers=0):\n",
    "    import copy_zoobot_weights\n",
    "\n",
    "    # load an object detection model pre-trained for Zoobot\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
    "        weights='COCO_V1',\n",
    "        trainable_backbone_layers=3\n",
    "    )\n",
    "\n",
    "    model = copy_zoobot_weights.copy_Zoobot_clumps_weights_to_Resnet(\n",
    "        model=model, \n",
    "        ckpt_path=CKPT_PATH + CKPT_NAME,\n",
    "        device=TORCH_DEVICE,\n",
    "        trainable_layers=trainable_layers\n",
    "    )\n",
    "    \n",
    "    # get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    \n",
    "    # replace the pre-trained head with a new on\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features,num_classes)\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/env_torch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/env_torch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "NUM_EPOCHS = 120\n",
    "\n",
    "# get the model, all pretrained layers from the backbone CNN are freezed\n",
    "frcnn_model = get_model(num_classes=5, trainable_layers=0)\n",
    "\n",
    "# move model to the right device\n",
    "frcnn_model = frcnn_model.to(TORCH_DEVICE)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in frcnn_model.parameters() if p.requires_grad]\n",
    "# optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "optimizer = torch.optim.Adam(params, lr=0.001, weight_decay=0.0005)\n",
    "\n",
    "# and a learning rate scheduler which decreases the learning rate by # 10x every 3 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.fpn.inner_blocks.0.0.weight\n",
      "backbone.fpn.inner_blocks.0.0.bias\n",
      "backbone.fpn.inner_blocks.1.0.weight\n",
      "backbone.fpn.inner_blocks.1.0.bias\n",
      "backbone.fpn.inner_blocks.2.0.weight\n",
      "backbone.fpn.inner_blocks.2.0.bias\n",
      "backbone.fpn.inner_blocks.3.0.weight\n",
      "backbone.fpn.inner_blocks.3.0.bias\n",
      "backbone.fpn.layer_blocks.0.0.weight\n",
      "backbone.fpn.layer_blocks.0.0.bias\n",
      "backbone.fpn.layer_blocks.1.0.weight\n",
      "backbone.fpn.layer_blocks.1.0.bias\n",
      "backbone.fpn.layer_blocks.2.0.weight\n",
      "backbone.fpn.layer_blocks.2.0.bias\n",
      "backbone.fpn.layer_blocks.3.0.weight\n",
      "backbone.fpn.layer_blocks.3.0.bias\n",
      "rpn.head.conv.0.0.weight\n",
      "rpn.head.conv.0.0.bias\n",
      "rpn.head.cls_logits.weight\n",
      "rpn.head.cls_logits.bias\n",
      "rpn.head.bbox_pred.weight\n",
      "rpn.head.bbox_pred.bias\n",
      "roi_heads.box_head.fc6.weight\n",
      "roi_heads.box_head.fc6.bias\n",
      "roi_heads.box_head.fc7.weight\n",
      "roi_heads.box_head.fc7.bias\n",
      "roi_heads.box_predictor.cls_score.weight\n",
      "roi_heads.box_predictor.cls_score.bias\n",
      "roi_heads.box_predictor.bbox_pred.weight\n",
      "roi_heads.box_predictor.bbox_pred.bias\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in frcnn_model.named_parameters():\n",
    "    if parameter.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [ 0/20]  eta: 0:02:35  lr: 0.000054  loss: 72.0398 (72.0398)  loss_classifier: 18.8892 (18.8892)  loss_box_reg: 0.0179 (0.0179)  loss_objectness: 53.0913 (53.0913)  loss_rpn_box_reg: 0.0414 (0.0414)  time: 7.7972  data: 1.4673\n",
      "Epoch: [0]  [10/20]  eta: 0:01:00  lr: 0.000579  loss: 5.0756 (18.4802)  loss_classifier: 0.2344 (3.4928)  loss_box_reg: 0.0331 (0.0449)  loss_objectness: 4.7253 (14.8405)  loss_rpn_box_reg: 0.1058 (0.1022)  time: 6.0178  data: 0.1348\n",
      "Epoch: [0]  [19/20]  eta: 0:00:05  lr: 0.001000  loss: 5.0756 (15.2605)  loss_classifier: 0.2127 (2.5701)  loss_box_reg: 0.0309 (0.1189)  loss_objectness: 4.7253 (12.3517)  loss_rpn_box_reg: 0.0876 (0.2198)  time: 5.7130  data: 0.0749\n",
      "Epoch: [0] Total time: 0:02:14 (6.7135 s / it)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [0/5]  eta: 0:00:21  model_time: 3.1385 (3.1385)  evaluator_time: 0.0011 (0.0011)  time: 4.3370  data: 1.1971\n",
      "Test:  [4/5]  eta: 0:00:03  model_time: 2.9361 (2.8143)  evaluator_time: 0.0006 (0.0007)  time: 3.0552  data: 0.2398\n",
      "Test: Total time: 0:00:35 (7.0575 s / it)\n",
      "Averaged stats: model_time: 2.9361 (2.8143)  evaluator_time: 0.0006 (0.0007)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Epoch: [1]  [ 0/20]  eta: 0:02:33  lr: 0.001000  loss: 8.9019 (8.9019)  loss_classifier: 4.9037 (4.9037)  loss_box_reg: 0.9035 (0.9035)  loss_objectness: 2.9971 (2.9971)  loss_rpn_box_reg: 0.0976 (0.0976)  time: 7.6826  data: 1.3535\n",
      "Epoch: [1]  [10/20]  eta: 0:00:59  lr: 0.001000  loss: 44.3910 (69.0624)  loss_classifier: 14.6555 (20.0205)  loss_box_reg: 3.4070 (3.8467)  loss_objectness: 20.7813 (43.2928)  loss_rpn_box_reg: 0.7255 (1.9024)  time: 5.9347  data: 0.1241\n",
      "Epoch: [1]  [19/20]  eta: 0:00:05  lr: 0.001000  loss: 24.2076 (46.5304)  loss_classifier: 5.0035 (14.7077)  loss_box_reg: 1.2508 (2.6378)  loss_objectness: 11.0968 (27.8661)  loss_rpn_box_reg: 0.5188 (1.3189)  time: 5.7450  data: 0.0690\n",
      "Epoch: [1] Total time: 0:02:14 (6.7455 s / it)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [0/5]  eta: 0:00:22  model_time: 3.1973 (3.1973)  evaluator_time: 0.0012 (0.0012)  time: 4.4230  data: 1.2243\n",
      "Test:  [4/5]  eta: 0:00:03  model_time: 3.1226 (2.9662)  evaluator_time: 0.0006 (0.0007)  time: 3.2124  data: 0.2452\n",
      "Test: Total time: 0:00:36 (7.2143 s / it)\n",
      "Averaged stats: model_time: 3.1226 (2.9662)  evaluator_time: 0.0006 (0.0007)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Epoch: [2]  [ 0/20]  eta: 0:02:50  lr: 0.001000  loss: 9.0253 (9.0253)  loss_classifier: 0.7234 (0.7234)  loss_box_reg: 0.2178 (0.2178)  loss_objectness: 7.4876 (7.4876)  loss_rpn_box_reg: 0.5965 (0.5965)  time: 8.5123  data: 1.2723\n"
     ]
    }
   ],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(\n",
    "        frcnn_model, \n",
    "        optimizer, \n",
    "        train_data_loader, \n",
    "        TORCH_DEVICE, \n",
    "        epoch, \n",
    "        print_freq=10,\n",
    "        scaler=None,\n",
    "        tb_writer=writer\n",
    "        # tb_writer=None\n",
    "    )\n",
    "    \n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    # evaluate on the test dataset\n",
    "    coco_evaluator = evaluate(\n",
    "        frcnn_model, \n",
    "        valid_data_loader, \n",
    "        device=TORCH_DEVICE\n",
    "    )\n",
    "    for iou_type, coco_eval in coco_evaluator.coco_eval.items():\n",
    "        writer.add_scalar(\"AP/IoU/0.50-0.95/all/100\", coco_eval.stats[0], epoch)\n",
    "        writer.add_scalar(\"AP/IoU/0.50/all/100\", coco_eval.stats[1], epoch)\n",
    "        writer.add_scalar(\"AP/IoU/0.75/all/100\", coco_eval.stats[2], epoch)\n",
    "        writer.add_scalar(\"AP/IoU/0.50-0.95/small/100\", coco_eval.stats[3], epoch)\n",
    "        writer.add_scalar(\"AP/IoU/0.50-0.95/medium/100\", coco_eval.stats[4], epoch)\n",
    "        writer.add_scalar(\"AP/IoU/0.50-0.95/large/100\", coco_eval.stats[5], epoch)\n",
    "        writer.add_scalar(\"AR/IoU/0.50-0.95/all/1\", coco_eval.stats[6], epoch)\n",
    "        writer.add_scalar(\"AR/IoU/0.50-0.95/all/10\", coco_eval.stats[7], epoch)\n",
    "        writer.add_scalar(\"AR/IoU/0.50-0.95/all/100\", coco_eval.stats[8], epoch)\n",
    "        writer.add_scalar(\"AR/IoU/0.50-0.95/small/100\", coco_eval.stats[9], epoch)\n",
    "        writer.add_scalar(\"AR/IoU/0.50-0.95/medium/100\", coco_eval.stats[10], epoch)\n",
    "        writer.add_scalar(\"AR/IoU/0.50-0.95/large/100\", coco_eval.stats[11], epoch)\n",
    "\n",
    "    model_save_path = MODEL_DIR + MODEL_NAME + '_' + str(epoch+1) + '.pth'\n",
    "    torch.save(frcnn_model.state_dict(), model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c186b54c8cf1ccf367fb8bdf3e071efe85839a5daed090332edb040d14e1fa50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
